## 제7장 챗봇: 챗GPT, 1분 안에 보고서 작성해 줘

#### 챗봇 이루다는 왜 2주 만에 서비스를 멈췄을까?
- 2020년 국내 스타트업이 런칭한 '이루다'는 자유 주제 대화 시스템(Open-Domain Dialogue System)
- 1966년 MIT의 컴퓨터 과학자 요제프 바이첸바움(Joseph Weizenbaum)은 세계 최초의 챗봇 일라이자(ELIZA) 개발
    - if-then 규칙 기반으로 구현되어 상대방이 사용한 문장의 핵심 어구를 추출해서 내부적으로 미리 정한 문장에 끼워 되묻는 방식
    - 매우 단순한 형태의 인공지능이었으며 가끔 아무 의미없는 말을 반복하기도 했지만 컴퓨터와 대화한다는 발상만으로 사람들은 놀랐고 결과는 꽤나 성공적
    - 이런 성과 덕분에 잠시 인공지능에 대한 낙관주의가 널리 퍼졌지만 그 이후 인공지능 분야는 별다른 성과를 내지 못함
- 이루다는 딥러닝을 활용해 카카오톡 대화를 학습해 풍부한 대화 가능했지만 개인정보보호법 위반으로 겨우 2주만에 서비스 중단
    - 이용자들의 개인적인 대화까지 학습에 동원
- 규칙 기반 챗봇은 규칙을 바꾸기만 하면 되는 것과 달리 이루다와 같은 딥러닝을 기반으로 한 인공지능은 어떤 말을 할지 필터링하기가 어려움
    - MS 테이 사례 : 트위터 사용자들과 대화하며 학습하도록 디자인되었는데 이 사실이 알려지자 많은 사람들이 테이에게 차별, 혐오, 욕설을 가르치기 시작해서 부적절한 말을 하기 시작함 > 결국 출시 16시간만에 운영 중단
- 챗봇 같은 생성 모델에는 사회적 파장 때문에 사소한 실수조차 용납되지 않음(그런 면에서 자율주행차와 비슷)


#### 컴파일러, 컴퓨터가 인간의 언어를 이해하다
- `컴파일러(Compiler)`: 한 언어를 다른 언어로 바꿔주는 과정
- 컴파일러의 개념은 컴퓨터 역사에서 아주 중요한 의미
    - 컴파일러가 등장하면서 비로소 컴퓨터는 계산기를 넘어 비즈니스에도 활용할 수 있는 만능 기계의 모습을 갖춤
- 여성 해군 제독 그레이스 호퍼(Grace Hopper)는 사람과 대화하듯 영어로 명령어를 입력하면 컴퓨터가 이해할 수 있는 언어로 바꿔주는 컴파일러 개념 고안
    - 과거 컴퓨터 프로그래밍은 컴퓨터에 기계어를 직접 입력하는 작업을 뜻했으나 기계별로 다른 기계어를 사용해서 호환성이 떨어졌으며 문제 발생 시 원인을 찾기 어려웠음
    - 코볼(COBOL)이라는 프로그래밍 언어가 탄생하는데 핵심적인 역할을 함
    - 회계, 매출 등 사무업무를 영어로 기술하면 컴파일러가 알아서 기계어로 바꿔줘서 수많은 사무용 SW가 등장함
- 컴파일러는 정해진 규칙에 따른 제한적인 명령만 이해할 수 있었고 자연어를 이해하진 못함


#### 카카오뱅크 고객센터 챗봇의 등장
- 범용 인공지능이 완성된다는 것은 인간이 내뱉는 모든 질문에 마치 사람처럼 자연스럽게 답변을 할 수 있는 것(인간이 할 수 있는 모든 지적 작업을 이해할 수 있는 능력)
- 챗봇은 FAQ 방식에 문장 유사도 판별 알고리즘을 활용


#### 좌표, 기하학을 숫자로 바꾸다
- 17세기 이전까지 수학은 기하학(Geometry)과 대수학(Algebra)으로 분류했으며 서로 다른 영역으로 취급함
- 르네 데카르트(Rene Descarte)는 <방법서설>에서 좌표(Coordinates)라는 개념을 공개
- 좌표라는 개념을 통해 서로 다른 분야라고 여겨진 기하학과 대수학의 개념을 하나로 합침
    - 사람은 기하학을 이해하는게 쉽지만 컴퓨터는 그림을 이해하는 게 어렵기 때문에 대수학이 오히려 더 쉬움(모라벡의 역설 once again)
- 미국의 수학자 클로드 섀넌(Claude Shannon)은 MIT 대학원생 시절 이진법을 이용해 모든 계산을 할 수 있는 디지털 논리회로의 개념을 고안해냄
    - 0과 1, 두개의 숫자로 모든 계산을 해낼 수 있게되었으며 정보의 개념을 수학적으로 정의(단위는 Bit)
    - 이후 정보 이론이라는 새로운 학문이 탄생했고 정보통신의 시대가 시작됨

- 정리하지면...
1. 데카르트의 좌표 덕분에 기하학을 방정식과 숫자로 표현할 수 있게 됨
2. 섀넌의 디지털 논리회로와 정보 이론 덕분에 컴퓨터는 모든 정보와 숫자를 계산할 수 있게 됨

- 인간의 언어를 숫자로 표현해낼 수 있다면 컴퓨터가 계산을 할 수 있을텐데 이를 어떻게 표현해야 될까?
    - 단어의 뜻에 대한 특징을 추출해 수치화하고 단어의 의미가 비슷하다는 것을 숫자로 표현해 그 값이 얼마나 가까운지 판별토록 처리함
    - 언어를 숫자로 표현하는 것 = 자연어 처리 분야에서는 언어를 '벡터'로 표현한다고 말함


#### 워드투벡, 언어를 숫자로 바꾸다
- `워드투벡(Word2Vec)` : 단어의 의미를 벡터로 표현하는 방법(2013년 구글이 발표)
    - 단어 각각의 특징을 추출해 관련이 없으면 가중치를 낮게 관련이 높다면 가중치를 높게 주며 수치화하는 과정
    - 많은 문장을 학습한 컴퓨터가 자동으로 단어의 값을 지정하고 좌표를 통해 특징을 위치로 구분해서 유사도 판별(유사한 단어 가까운 숫자로 표현)
    - 관계에 대한 정의도 가능(e.g. 남자-여자, 왕-여왕)


#### 코사인 거리로 비슷한 단어를 찾다
- 단어간 유사도는 벡터와 벡터 사이의 직선거리로 판별할 수 있음
    - `유클리드 거리`: 점과 점 사이의 직선거리
- 하지만 벡터 공간의 크키가 달라지면 거리도 달라지기 때문에 두 점의 각도를 측정한 `코사인 거리` 활용


#### 기계와 자유롭게 대화할 수 있을까?
- 챗봇이 `문제해결용 대화시스템(Task-Oriented Dialogue System)`에서 `자유 주제 대화 시스템(Open-Domain Dialogue System)`으로 가려면 어떤 과정을 거쳐야 할까?
- 앨런 튜링은 <계산 기계와 지능>에서 '기계는 인간이 시키는 일만 할 수 있다'는 러브레이스의 견해를 반박
    - e.g. 알파고에게 그 누구도 세계 챔피언을 이길 수 있는 전략을 알려주지 않았지만 스스로 해냄


#### 기계가 문장을 생성하는 방법
- [과거] 템플릿 기반으로 문장을 생성해 몇가지 단어나 숫자를 교체하며 대답 -> [현재] 딥러닝이 직접 대화와 응답 데이터를 학습하여 스스로 대화의 규칙을 찾아냄
- `엔드투엔드 방식(End-to-End)`: 문장을 입력하면 바로 출력 문장을 생성하는 방식
    - 모든 중간 과정을 기계가 자동으로 처리하기 때문에 사람이 개입할 필요가 없으며 아무런 규칙을 부여하지 않아도 다양한 유형의 질문에 적절한 답변 생성 가능


#### GPT-3, 인간을 능가하는 언어 생성 모델
- 2015년, 인류에 이익이 되는 범용 인공지능(Artificial General Intelligence, AGI) 개발을 목표로 한 오픈AI 발족
- 오픈AI의 대표적인 산물, 언어 생성 모델 GPT(Generative Pretrained Transformer)
    - 자동으로 학습할 수 있는 전통적인 '언어 모델'. 문장 생성에 최적화 되었다고 해서 '언어 생성 모델'이라고 부르기도 함
     - 기계번역 모델인 트랜스포머에서 디코더만 가져와서 응용했으며 워드투벡과 달리 문장의 다음 단어가 나올지 맞추도록 학습한 모델
- 처음 공개된 GPT는 별로 주목 받지 못했지만 GPT-2부터 모델의 크기를 키우고 데이터를 늘리자 성능이 좋아짐
- GPT-3는 인터넷에 있는 방대한 데이터를 모조리 학습해서 문장을 넘어 데이터의 생성 원리를 이해하게 됨(데이터의 구조를 암기하고 생성할 확률을 정교하게 계산)
- 오픈AI는 GPT-3를 유료 API로 제공하기로 결정. 소스코드에 접근할 권한은 회사에 투자해준 MS에게만 독점적으로 부여
- 네이버 하이퍼클로바는 GPT-3보다 많은 2,040억개의 매개변수 채택, 6500배 많은 한국어 데이터 학습시켜 한국어에 최적화된 언어 모델 구축


#### 구글과 페이스북의 챗봇이 등장하다
- GPT-2 공개 직후 트랜스포머 모델을 기반으로 다양한 챗봇 등장
    - 구글 Meena, 페이스북 Blender Bot도 GPT-2 이후 출시
    - 블렌더봇은 인격과 지식, 공감의 특성을 생성하고 조합해서 훨씬 더 폭넓은 대화 가능했으며 검색과 생성을 섞어 고품질의 응답을 생성했는데 그 결과 사용자가 구글의 미나보다 블렌더봇을 더 선호


#### 챗GPT, 챗봇 끝판왕의 등장
- GPT-3, 초거대 모델이라고 해도 그 다음 단어가 무엇인지를 예측하는 단순 확률 모델일 뿐이지만, 오픈AI가 목표하는 범용 인공지능을 개발하기 위해서는 챗봇은 빠질 수 없는 기술
    - 다만, 단순히 데이터의 크기만 키운다고 좋은 챗봇이 되는게 아니라 영리하게 답하는 챗봇을 만들기 위해서는 별도 장치 필요
    - 따라서, 오픈AI는 GPT가 '사용자 프롬프트(User Prompts)'를 잘 따르도록 튜닝
- 인스트럭트GPT(Instruct GPT): 챗GPT의 이전 모델로 사용자 프롬프트를 잘 따를 수 있도록 3단계 과정을 거쳐 GPT-3를  업그레이드 한 모델
    - 1단계) 데이터셋을 구축해 지도 미세 조정 모델(Supervised Fine-Tuning, SFT)을 학습하는 단계
        - GPT-3에 인간이 세심하게 정제한 데이터를 넣고 튜닝
    - 2단계) 비교 데이터를 구축하고 보상 모델(Reward Model, RM)을 학습
        - 하나의 질문에 대해 여러 답변을 두고 어떤 답변이 만족스러운지 순위를 매기는 과정
    - 3단계) 강화학습을 통해 성능을 높이는 단계
        - 강화학습의 보상을 반영하는 알고리즘인 PPO 알고리즘 활용
        - 가장 어려운 단계. SFT모델이 출력한 문장을 RM모델이 확인해서 사람들이 얼마나 선호하는지 평가한 후, 선호하면 보상을 많이 주고 비선호이면 보상을 적게 줌. 그리고 받은 보상을 모델에 반영할 때 PPO 알고리즘 활용해서 다시 SFT모델에 반영해서 PPO 모델 구축
            - 알파고가 강화학습으로 알파고끼리 대국을 치르며 스스로 학습한 방식과 동일
            - `RLHF(Reinforcement Learning from Human Feedback)`: 인간의 피드백을 이용한 강화학습
    - 이를 통해 SFT 모델은 사람이 가장 선호하고 가장 그럴듯한 대답을 하는 PPO 모델로 재탄생 = 인스트럭트GPT
    - 하지만 인스트럭트GPT의 단점은 무슨 말을 할지 예측이 되지 않는다는 점(위험한 말이나 틀린 말 등)
        - 따라서, 오픈AI는 데이터 수집 설정을 보완하고 데이터 작업자들을 다양한 인종과 성별로 구성해 최대한 중립을 지키는 말을 하도록 보완
        - 중재 역할을 하는 API도 도입해서 폭력, 증오, 성적인 내용 등을 사전에 분류해서 제어
        - 잘못된 정보를 사전에 팩트 체크하도록 안전 모듈 강화
    - 이 과정을 거쳐 완성한 모델이 챗GPT
    - 2022년 11월 오픈AI는 챗GPT를 세상에 공개
        - 가장 놀라운 점 하나는 MS의 지원 덕분에 전세계를 대상으로 공개 베타 서비스를 진행할 수 있었다는 점
        - 출시 5일 만에 사용자 100만명 돌파(역대 가장 빠른 기록)
    - MS는 자사 검색엔진 Bing에 챗GPT를 접목해서 전세계 검색 트래픽의 94%를 독점하고 있는 구글에 도전


#### GPT-4, 마침내 진정한 인공지능의 시대에 다가서다
- 그동안 GPT는 1년 주기로 새로운 버전을 출시했는데 GPT-4는 GPT-3 이후 3년 만에 등장
- GPT-4는 월등히 뛰어난 성능을 보여줌(뉴욕주 변호사 시험에 합격할 수 있는 수준)
    - 글자를 비롯해 이미지도 잘 이해하게 됨
- GPT-4 이후 오픈AI는 관련 기술을 공개하지 않기로 결정
    - 기존에는 기술 공개 및 연구 논문 공개
- 오픈AI가 기술공개를 하지 않는다는 것은 아래 두가지 사항을 의미함
    1. 언어 모델은 연구단계를 넘어 제품화 단계에 돌입. 기술을 공개하는 것보다는 제품의 완성도를 높이는 방향을 택함
    2. 연구 성과로 공개할 내용이 많지 않음. 새로운 연구를 GPT에 적용했다기보다 고품질의 데이터를 사용하고 안전 모듈을 크게 강화함(근간 기술은 인스트럭트GPT와 동일)


#### 기계가 언어를 이해할 수 있을까?
- `질의응답(Question Answering)`: 질문을 입력하면 정답을 한번에 찾아내는 기술
    - 질의응답은 기계번역과 함께 자연어 처리 연구의 대표적 난제 중 하나
- `BERT`: 구글에서 개발한 언어를 이해하는 가장 유명한 모델
    - GPT는 트랜스포머의 디코더와 버트를 인코더로 채택
    - 워드투벡처럼 문장의 의미를 벡터로 표현하기 위해 많은 문장을 학습해서 사전 지식을 활용해 모델의 정확도를 높이는 모델
    - `전이 학습(Transfer Learning)`: 미리 학습한 사전 지식을 그대로 이전해서 활용하는 것
- 이제는 질의응답 문제를 해결하기 위해 사전 지식을 그대로 활용하면서 문제해결을 위한 약간의 학습만 하면 좋은 성능을 낼 수 있음
- 버트는 질문을 숫자로 변환한 값을 입력값으로 받아서 계산하고 본문에서 정답의 위치를 확률적으로 계산


#### 튜링 테스트와 중국어 방
- 앨런 튜링은 논문 <계산 기계와 지능>에서 이미테이션 게임 제안
    - 인간이 생각한다고 여기는 행동을 기계가 흉내낼 수 있다면 이를 '생각한다'고 판정하자고 제안(= Imitation game = Turing test)
- 과연 튜링 테스트를 통화하면 기계가 생각하는 것일까?
    - UC 버클리 존 설(John Searle) 교수는 1980년 중국어 방 사고 실험을 통해 튜링 테스트를 비판
    - 중국어 방(Chinese Room) 사고 실험:
        1. 중국어를 모르는 사람을 방에 들어가게 한 후 중국어로 된 질문과 대답이 적힌 책, 필기도구 제공
        2. 한쪽에서 중국어로 질문을 써서 넣으면 방안에 있는 사람은 중국어 책에서 답을 찾아 쪽지를 반대편에 전달
        - 이렇게 하면 중국어를 모르는 사람도 튜링 테스트를 통과할 수 있지만 과연 그 사람이 중국어를 이해하는거라고 말할 수 있을까?
    - 존 설은 방안에 있는 사람이 중국어 질문을 이해한다고 볼 수 없으며 그렇기 때문에 비슷하게 행동하는 기계 또한 생각한다고 볼 수 없다고 주장
- 2025년 4월, GPT-4.5 튜링테스트 첫 통과([기사])(https://www.chosun.com/economy/science/2025/04/08/2E66J7UA6NESHIQB6HLFPEFTVA/)
    - GPT에 페르소나를 부여해 채팅해 본 실험 참가자들이 실제 사람으로 오인한 승률이 73% (50% 이상이면 튜링 테스트 통과로 간주)


#### 인공지능이 진정한 이해를 묻다
- 컴퓨터가 인간 수준의 지능을 갖고 있는지 테스트하려면 튜링 테스트만으로 부족하다는 비판과 달리 미래학자 레이 커즈와일은 튜링 테스트만으로도 충분하다고 주장
    - 커즈와일은 2029년 튜링 테스트를 통과하는 컴퓨터가 나올 것으로 예측
    - <특이점이 온다>에서 특이점이 오는 시기를 2045년 전후로 예상
        - 특이점(Singularity)이란 기계가 인간 지능을 추월하는 시점을 의미
    - 커즈와일은 존 실의 컴퓨터가 기호만 조작할 뿐 기호의 의미를 이해 못한다는 주장은 우리 뇌가 신경 간 연결 시냅스 세기를 조작하기만 할 뿐 그 의미는 이해하지 못한다는 말과 똑같다며 그렇다면 인간의 뇌도 진정으로 어떤 것도 이해하지 못한다는 결론을 내려야 한다고 주장
- 1979년 인디애나대 더글러스 호프스태더 교수는 <괴델, 에셔, 바흐>라는 예술과 과학을 결합한 책에서 인공지능 연구가 인간 의식에 관한 근본적인 질문은 잊어버린 채 온통 기술 중심으로만 개발되고 있는 현실에 불편을 표함
    - 의미 있는 인공지능을 만드는 유일한 방법은 인간의 상상력이 작동하는 방식을 이해하는 것이라고 믿음 
    - 아쉽게도 주류 인공지능 연구와 다르게 가정, 유추, 비유 같은 뇌의 고차원적 작동 원리를 탐구한 호프스태터의 접근 방식은 21세기에 들어 거의 폐기됨
    - 계산 능력은 성과를 잘 낸 반면 상상력에 관한 연구자들의 관심은 희미해짐
- 언어를 진정으로 이해한다는 것은 무엇을 의미할까?
    - 커즈와일은 '통계적 분석 과정을 거쳐 언어를 비록한 여러 현상을 이해하는 것을 진정한 이해가 아니라고 한다면, 인간 또한 같은 방식으로 이해하기 때문에 진정으로 이해하는 것은 감히 아무것도 없다고 할 수 있다'라고 주장


> #### ***comments***
> - p.297 고수준 언어(자바, 파이썬), 저수준 언어(기계어)는 왜 이렇게 분류되는건가?
> - p.326 매개변수를 더 많이 채택한다는 것은 무슨 의미일까?
> - p.331 응답 품질과 응답 최소 길이 제한의 상관관계는 뭘까?
> - p.337 좋은 데이터를 구축하기 위한 오픈AI의 노력들 찾아보기
> - 어떤 기술적 설명은 중간에 맥락이 뚝 끊기는 느낌이 있었음
> - 인공지능에 대해 공부할수록 기술적인 풀이에 대해 머리가 아프기보다 철학 질문을 하느라 머리가 아프다 마치 철학 박사하는거 같은 느낌...

> #### ***food for thought***
> - 인간이 이해한다는 것은 무엇을 의미하나? 기계가 인간이 뛰어넘었다는 것을 어떤 기준으로 측정할 것인가?
> - 개인적으로 존 설의 중국어 방 사고실험에 대한 주장에 더 공감이 되는 것 같다. 결국 인간의 뇌가 주고 받는 뉴런의 신호들도 전자 신호임을 따져본다면 생각과 감정은 전자 신호일 뿐인거 아닌가?
>    - 그리고 결국 인간도 진짜로 모든건 이해하고 행동하는 건 아닌것 같음
>    - 다만, 인간과 기계의 차이점은 인간은 자의를 가지고 행동한다는 점과 기계는 그렇지 않다는 점 아닐까? 아직까지는 인공지능은 사람이 실행시키고 사용해야 의미가 있는 기술일 뿐
> - 아울러 폐기되었다고 하지만 호프스태터가 연구한 상상이나 창의성 같이 뇌의 고차원적 작동 원리까지 구현이 되어야 인간처럼 이해하고 생각한다고 정의 할 수 있을 것
>    - 인공지능 기술이 고도화 되는 현시점에서 튜링 테스트만으로 기계가 인간처럼 생각한다라는 판단을 하기엔 부족해보이며 새로운 기준이 필요한 시점인 듯