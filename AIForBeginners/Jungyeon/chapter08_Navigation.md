## 제8장 내비게이션: 티맵은 어떻게 가장 빠른 길을 알까

#### 내비게이션, 당신의 스마트한 운전 비서
- 과거 운전이란 자동차를 동작시키는거 외 뇌의 특정 영역을 활용해 지리 정보와 경로 계획을 끊임없이 떠올리는 복합적인 활동(뇌의 해마 발달)
    - 택시운전사들은 경로를 계산하는 훈련을 매일 하니 해마가 커짐, 실제 택시운전자격시험에는 운행 지역의 지리 시험이 포함

- 네비게이션 시스템이 발달되게 된 2가지 터닝포인트
    1) 미국, 정확한 GPS 신호 민간 개방
        - 1970년대 군사적 목적으로 GPS 위성을 쏘아올림. 보안 상 이슈로 최대 100m 이상 오차가 나게 만듦
        - 2000년 클린턴 정부 때 오차를 없애면서 민간에서 적극 활용할 수 있게 됨 
    2) 네비게이션 시스템, 교통정보와 머신러닝까지 연동되며 더욱 스마트해짐
        - 현재 위치만 알려주던 네비 시스템이 실시간 교통정보와 연동되며 이제 최적 경로 안내 가능

- 자율주행차에는 오차 10cm 단위의 고정밀 지도 필수
- 국내 도로상황을 빠르게 반영하고 운영하는지 여부 매우 중요
    - 따라서 국내 상황에 익숙치 않은 해외 업체가 진출하기 어려움
- 최근에는 주유 중, 서비스센터 정부 중 지도파일 자동 업데이트 가능


#### 오컴의 면도날 법칙
- "모든 모델은 잘못됐다. 그러나 일부는 유용하다."
    - 어떤 모델도 현실 세계를 완벽하게 기술하지는 못한다라는 뜻

- 규칙 단순할수록 좋음 (즉, 매개변수 적을 수록 좋음)
    - 매개변수가 늘수록 그만큼 규칙을 조정할 여지가 늘면서 더 정교한 모델이 되지만 계산이 까다로워짐
    - 매개변수가 하나씩 늘어날 때마다 학습 데이터가 훨씬 더 많이 필요함
    - 따라서 크고 복잡한 모델이 항상 좋은 것만은 아니며 오히려 `과적합(Overfitting) `에 빠질 수 있음
        - `과적합(Overfitting) ` : 학습 데이터를 과하게 학습하여 이에 대한 오차는 감소하지만 과적합 문제로 인해 실제 데이터에 대한 오류는 증가해 일반화 성능은 떨어지게 되는 것
    - 복잡하고 정교한 규칙은 만들 수 있지만 어느 수준까지 가면 충분히 정확한 정도가 있음
- `오컴의 면도날(Occam's Razor)` : 면도날로 도려내듯 단순한 모델이 최선이라는 원칙
    - 필요 이상으로 많은 것을 가정하지 말라는 라틴어 문구에서 유래
    - 과학계에서는 여러 가설 중 가장 단순한 것이 대개 진실에 가까울 가능성이 높다고 가정
    - 매개변수가 늘어나 과적합하는 현상을 경계해야 됨
        - "With four parameters I can fit an elephant, and with five I can make him wiggle his trunk." John von Neumann, 수학자 & 컴퓨터과학자


#### 예측을 좌우하는 데이터
- **데이터의 분포** : 확률적 데이터에서 어떠한 값이 자주 나오고 어떠한 값이 드물게 나오는가를 나타내는 정보
- 과거 미국의 신용 평가사들은 주택 가격은 꾸준히 상승한다는 데이터를 기반으로 평가모델을 만들었는데 2008년 서브 프라임 모기지 사태가 발생하자 신용 평가 모델은 신용 위험을 산정하는데 아무런 소용이 없었음
- 특정 사례에 대한 데이터가 없다면 해당 사례를 제대로 예측할 수 없음

- **데이터 불균형** : 데이터의 비율이 균일하지 않고, 한쪽으로 치우친 데이터
    - 상대적으로 비중이 적은 데이터를 사용하면 정확도가 떨어짐(e.g. 수만장의 데이터를 학습해도 암을 포착한 사진 데이터를 수십개 밖에 못봤다면, 암 예측 능력 떨어짐)
    - 학습데이터가 균형 있게 구성되거나 불균형을 해소할 특별 알고리즘 필요

- 인공지능의 편향(Bias) : 데이터의 분포나 불균형을 해소하지 못할 경우, 의도치 않게 잘못된 방향으로 치우치는 편향이 생겨서 차별을 하게 됨
    - 인공지능이 의도적으로 차별하는게 아니라 인간의 편견을 학습하게 되어서 차별 행동 발생


#### 의사결정나무, 단순한 모델의 힘
- `의사결정나무(Decision Tree)` : 예/아니오로 답할 수 있는 질문을 해서 조건에 따라 분기하는 모델
    - 질문의 횟수는 적을 수록 좋으며 가급적 정답을 빨리 맞힐 수 있는 질문을 먼저 제시해야 효과적
    - 의사결정나무는 가장 정답에 가까운 질문을 먼저하는 식으로 엔트로피를 낮추는 질문을 이어나가면서 빨리 정답을 맞추는 원리
        - ` 엔트로피(Entropy)`: 복잡도 또는 불확실성의 정도. 엔트로피가 낮아지면 복잡도와 불확실성이 줄어들기 때문에 엔트로피를 낮춰 의사결정나무가 가급적 정답을 빨리 맞히도록 해야 함
    - 의사결정나무는 판별 과정이 투명하게 보이기 때문에 왜 그렇게 판단했는지 이유를 알 수 있으며 오류도 쉽게 발견할 수 있음(단순한 모델의 장점)
    - 단, 한번 잘못된 판단을 내리면 의사결정나무는 이를 스스로 수정할 수 있는 방법이 없기 때문에 한번의 오류에도 취약함.
    - 따라서 지나치게 엄격한 의사결정나무 모델은 예상 밖의 변화에도 민감하게 반응하므로 오류가 많은 현실의 데이터로 정확도를 높이기 어렵기 때문에 **랜덤포레스트** 활용
    

#### 랜덤 포레스트, 대중의 지혜를 발휘하다
- 2001년 버클리대 통계학자 레오 브라이만(Leo Breiman)이 오류에 견고한 랜덤포레스트 모델 제안
-  `랜덤포레스트(Random Forest)` : 데이터와 특징에 제한을 두고 샘플을 추출한 다음 여러 개의 의사결정나무를 만들어 각각의 결과를 두고 투표해 최종 결과를 정하는 방식
    - 데이터와 특징을 제한했기 때문에 단일 의사결정나무보다는 성능이 떨어지지만 의사결정나무의 양을 늘려 대중의 지혜를 발휘하도록 하는 모델



#### 그레이디언트 부스팅, 정답과 거리를 줄여나가다
- `잔차(Residual)` : 통계학에 잔차라는 개념은 오차와 비슷. 전체에 대한 오차가 아니라 샘플의 오차가 잔차
    - 잔차를 줄여나가면 모델을 훨씬 더 정교하게 개선할 수 있기 때문에 통계학에서 여러 모델을 만드는데 중요하게 사용
- ` 그레이디언트 부스팅(Gradient Boosting)` : 이전 모델의 약점을 보완하는 새로운 모델을 순차적으로 적합하여 잔차의 기울기를 줄여나가는 형식의 과정. 정답을 맞히기 위해 정답과의 거리를 줄여나가는 과정(like golf)
    - 랜덤 포레스트에서는 무작위로 여러개의 독립적인 나무를 만들었는데 그레이디언트 부스팅에서는 이전 나무에 크게 영향을 받는 새로운 나무를 만듦
    - 모델 제작 과정: 
        1) 의사결정나무 하나를 만듦
        2) 나무에서 오류가 발생하면 실수를 바로 잡는 새로운 나무를 만듦
        3) 1-2번 과정을 반복해서 오류를 최소화할 때까지 계속 반복
- 의사결정나무는 단순하지만 성능이 떨어지기 때문에 그레이디언트 부스팅을 통해 매우 높은 정확도를 내도록 보완
- 딥러닝이 많은 분야에서 좋은 성과를 내고 있지만 정형화된 데이터를 예측하는 일에서는 전통적인 머신러닝 모델인 랜덤 포레스트와 그레이디언트 부스팅이 여전히 좋은 성과를 냄
    - 랜덤 포레스트, 그레이디언트 부스팅을 응용한 모델은 교통 체증 분석, 배차 예측 등 여전히 여러 분야에서 활발히 활용됨


#### 데이크스트라 알고리즘, 최단 거리 탐색의 비밀
- `데이크스트라 알고리즘(Dijkstra's Algorithm)` : 현재 위치에서 주변을 모두 살핀 후 그 중 항상 최단 경로를 택하는 알고리즘. 단순하고 결과값을 찾는 속도가 매우 빠름
    - A - Z로 가는 최적 경로를 찾는 경우, 중간에 수많은 구간(A-B, B-C 등)을 탐색해서 최적 경로를 찾기 때문에 시간이 많이 걸림


#### 모든 내비게이션이 채택한 A* 알고리즘
- `A* 알고리즘(A* Algorithm)` : 데이크스트라 알고리즘의 확장판으로 꼭 필요한 경로만 탐색하여 탐색횟수를 줄이고 양방향 경로를 합산해서 최적의 경로를 찾음
    - 1968년 훗날 애플 시리를 만든 스탠포드연구소(SRI 인터내셔널)에서 개발
    - 출발지에서 도착지로 이동하는 시간 뿐만 아니라 도착지에서 출발지로 이동하는 시간도 포함해 계산
    - 교통 지연, 도로 체증, 공사 여부, 신호등, 직선거리 등 다양한 변수 활용 가능


#### 내비게이션, 경로 안내 그 이상의 것
- `브라에스 역설(Braess' Paradox)` : 새로 만든 도로에 차량이 몰리면서 교통 정체 상황이 도로 개통 이전보다 더욱 악화되는 상황
- 교통 시설 전체를 효율적으로 활용하려면 시간과 공간에 차량이 적절히 분포되어야 함
    - 따라서 네비게이션은 모든 차량에 동일한 최적 경로를 제공하기보다 다양한 경로를 제시할 필요
    - 네비게이션이 전체 교통 상황을 고려해 특정 사용자에게 최적이 아닌 경로를 안내해도 되는지에 대해서는 논란의 소지가 있음
    - 2017년 미국 대화재 때 네비게이션이 도로가 한산하다는 이유로 불이 난 도로로 사람들은 안내함. 이 사례처럼 아직 풀어야 할 문제도 많음


> #### ***comments***
> - 데이터 과학자들이 좋아한다는 말, "모든 모델은 잘못됐다. 그러나 일부는 유용하다.(All models are wrong, but some are useful.)"을 한 통계학자 George Box가 궁금해짐 
> - A* 알고리즘 왜 양방향을 검토하는게 효과적인지? 출발지와 도착지 사이의 경로를 탐색하는데 불필요한 경로는 제외한다고 할 때 불필요한거라는 건 어떤 걸 의미하는건지?
> - 내비게이션은 해외 업체가 진출하기 어렵다고 하는데 최근 우버를 사용하면서 교통 관련 분야에서는 국내 업체가 유리하다는 점을 실감함(핀 위치나 랜드마크 표기, 경로 등에 있어서 차이가 있는 것 같은 느낌)
> - 네비게이션을 만드는 개발자가 가장 똑똑한 개발자들이라는 말을 듣고 이번 챕터에 대한 기대가 좀 컸는데 이 책만 읽어서는 왜 그런지에 대한 의문이 해소되진 않음


> #### ***food for thought***
> - 이제는 네이버 지도에서도 실시간 정보를 주고 받을 수 있는 것 같지만 체감상 도입 시기가 좀 늦었던 것 같은 느낌. 우리나라에서는 왜 유저들이 실시간 정보를 주고 받을 수 있는 웨이즈 같은 서비스가 활성화되지 않았을까?
> - 브라에스 역설에 대한 설명을 읽으며 들은 생각. 새로운 기술은 편리하지만 실제 사용 과정에서 더 많은 시간, 노력이 소요되거나 불편함을 줄 때도 있다(Technology Paradox). 이런 경우 계속 사람들을 번거롭게 해서 쓰게 하는 것이 의미가 있나? 유용한 기술이니 불편함을 감수하면서라도 사용자들에게 계속 쓰도록 강요할지 말지에 대한 선을 어디에서 그을 수 있을까?(예: 아파트 쓰레기 처리기)