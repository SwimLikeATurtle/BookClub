## 제1장 인간을 능가하는 GPT-4

#### 들어가며
- 사람들은 GPT-4 출시부터 2016년 알파고가 세상을 놀라게 한 이후 두번째 빅 웨이브가 도래했다고 평함

- 하지만 아직 해결해야 될 문제는 많음. 챗GPT만 봤을 때 인공지능이 해결해야 될 주요 이슈들: 
    - 할루시네이션
    - 데이터 저작권의 문제
    - 악의적 활용에 대한 우려
    - 환경에 영향을 미치는 막대한 에너지 소모

- 인간은 과거 핵폭탄과 같은 치명적인 기술조차 현명하게 통제한 경험이 있음
    - 새로운 기술은 언제나 문제점을 안고 있지만 인류는 항상 이를 보완하며 발전을 거듭해옴. 인공지능도 다를게 없음
- 기술에 무조건 의존할 필요는 없지만 그렇다고 기술에 무작정 공포를 느낄 필요도 없음
- 기술이 우리 삶을 변화시키는 것은 분명하지만 그 변화를 어떤 방향으로 설계하고 통제할지는 결국 인간의 몫


#### 인간을 능가하는 GPT-4의 등장
- `초거대 언어 모델(Large Language Model, LLM)` : 
- GPT-4는 오픈AI가 개발한 초거대 언어 모델의 이름
	- 전에 챗GPT는 언어 모델 자체를 지칭하기도 했으나 이제는 챗GPT는 GPT 모델을 활용하는 챗봇 서비스의 이름
- 챗GPT 등장의 핵심은 전 세계를 대상으로 무료로 서비스한 점
	- 챗GPT 이전에도 챗봇과 비슷한 기술을 많았지만 생성형 인공지능의 위험성과 막대한 운영비용 탓에 감히 공개적으로 데모를 운영할 생각을 못함
	- 무료 서비스 배포를 통해 오픈AI는 경제적 해자(Economic Moat)를 구축. 높은 인지도를 빠르게 확보해서 역사상 가장 빠르게 성장한 서비스가 됨

-  챗GPT의 경쟁자
	- 오픈AI 출신 연구원들이 창업한 엔트로픽(Anthropic)
	- 프랑스에서 구글과 페이스북 출신 연구원들이 창업한 미스트랄(Mistral AI)

- 챗GPT 같은 서비스를 개발하는 데는 막대한 비용이 들기 때문에 대부분의 회사는 LLM을 외부에 공개하지 않음
	- 챗GPT도 서비스는 공개했지만 모델 자체는 공개하고 있지 않음
    - 다만, 메타의 저커버그는 오픈소스의 힘을 빋는다고 선언하며  GPT-4에 견줄 만한 성능을 가진 모델 Llama를 누구나 사용할 수 있도록 오픈소스로 공개
        - 메타가 Llama를 공개하는 것도 개발 커뮤니티 상에서 경제적 해자를 구축하려는 것일 것
	- 과거 리눅스가 오픈소스로 MS에 맞서 서버와 안드로이드 운영체제의 핵심으로 자리 잡은 것과 같이 메타도 Llama로 전 세계 다양한 서비스의 표준이 되길 기대

- 오픈AI는 인공지능이 인류를 멸망시킬 수 있을 것이라고 우려한 일론 머스크의 주도하에 설립된 회사
	- 오픈 AI의 목표는 어떤 집단이나 기업에 귀속되지 않는 `범용 인공지능(Artificial General Intelligence, AGI)` 개발
	- 구글이 딥마인드를 인수하자 걱정이 더욱 커져서 인공지능 발전의 올바른 방향을 제시하고자 설립한 비영리 연구소
	- 초기 비영리 단체를 표방하며 기부로 자금을 조달(무려 10억 달러)

-  `범용 인공지능(Artificial General Intelligence, AGI)` : 특정 작업에 특화된 인공지능이 아닌 인간 수준의 종합적인 사고 능력을 갖춘 인공지능. 즉, 인간처럼 다양한 작업을 이해하고 수행 가능

- 오픈AI 사업 초기에는 스스로 학습하는 강화학습 플랫폼을 만들었고 이후에는 아래와 같은 모델들 개발
	- 달리(DALL-E) : 이미지를 생성하는 모델인 달리
	- 위스퍼(Whisper) : 음성인식 모델
	- 코덱스(Codex, 현 Github Copilot) : 프로그래밍 코드 작성을 지원
	- 소라(Sora) : 동영상 생성 모델
	- GPT(Generative Pre-trained Transformer) : 가장 유명한, 챗GPT의 기반 모델. 구글 연구팀이 2017년에 발표한 트랜스포머 모델을 기반으로 2018년 오픈 AI가 사전 학습을 통해 공개한 생성형 인공지능 모델. GPT와 같은 모델을 LLM(초거대 언어 모델)이라고 함


#### GPT의 핵심인 언어 모델 살펴보기
- `언어모델(Language Model)` : 자연어의 확률적 모델. 언어의 구조와 패턴을 학습해 언어를 이해하고 생성할 수 있도록 설계된 모델. 인간의 언어를 컴퓨터로 모델링하는 여러 방식 중 하나
	- `자연어(Natural Language)` : 사람들이 일상적으로 사용하는 자연스럽고 직관적인 언어
	- 자연어 처리(Natural Language Processing) 분야에서 중요한 연구 주제 중 하나. 실제 언어를 처리하는 여러 분야에서 필수적으로 쓰이는 모델(음성인식, 기계번역, 필기인식 등)
- 1883년 프랑스 언어학자 미셸 브레알은 `의미론(Semantics)`이라는 개념을 제안. 현대의 인공지능 분야에서 사용되는 현대 언어모델 또한 '언어의 의미'를 중시한다는 점에서 의미론 개념을 활용
- 현대 언어 모델의 개념은 1980년 IBM에서 시작됨
	- 수많은 문장을 사용해 통계적인 방식으로 언어 모델을 구축했으며 단어의 번역 확률부터 문장 중간의 단어를 예측하는 모델, 다음 단어를 예측하는 모델까지 다양한 형태의 확률 모델을 만듦
- 가장 기본적인 언어 모델 방식 : 주어진 문맥을 바탕으로 다음에 올 가능성이 가장 높은 단어나 문장이 무엇인지 예측하는 모델
	- 앞에 나오는 문장을 함께 계산해서(for context) 다음에 등장할 단어를 계산하는 모델
- 그 결과 언어 모델은 강력한 예측 능력으로 자연스러운 문장을 만들고 문맥에 맞게 대화에 참여 또는 질문을 할 수 있는 것
	- 언어모델은 문장의 확률을 기반으로 잘못 인식된 부분을 보정해주는 역할도 함


#### 초거대 모델, 크기 전쟁을 시작하다
- LLM의 Large는 모델의 규모를 뜻함. 최근 언어모델들은 수천억 개 이상의 매개변수(Parameter)를 갖고 있음. 이처럼 모델의 규모가 커지면서 대규모 또는 초거대로 번역
	- 초기 GPT 모델의 매개변수는 1억여개 -> GPT-4는 1조 8천억개 
	- 인간 두뇌의 뉴런 개수는 860억 개. 
- 단, 매개변수가 뉴런보다 많다고 해서 인간보다 더 뛰어나다고 볼 수 없음. 혹자는 뉴런들을 잇는 시냅스까지 포함해서 매개변수가 320조 개는 넘어야 인간과 비슷한 성능이 될 것이라고 함
- 인간의 두뇌와 인공신경망의 구조가 동일하지 않기 때문에 어쩌면 매개변수의 크기가 중요한게 아닐 수 있음
	- 인공 신경망은 인간의 두뇌와 구조가 다름. 인간의 두뇌를 본떠 만들어졌지만 일치하진 않음. 마치 새를 본떠 비행기를 만들었지만 둘이 다른 것과 같음

- GPT의 핵심은 문장을 학습하는데 사람의 도움이 필요 없이 자동으로 이뤄진다는 점 
	- 언어 모델은 통계적 방법을 통해 꾸준히 발전해왔는데 대부분 특정 작업에 최적화된 데이터가 반드시 필요했음 aka 지도학습(Supervised Learning)을 해야 함
	- 지도학습을 위해서 학습 데이터를 구축해야 하는데 이 과정에서 사람이 일일이 판별하여 정답을 달아주는 라벨링(Labeling) 필요
		- GPT 또한 라벨링 데이터를 위해 인건비가 싼 케냐에 외주를 10개월 간 맡김
	- 문장(데이터)를 많이 모으고 싶어도 인원과 투입 시간에 비례할 수 밖에 없는 작업. 아울러 사람이 하는 일이라 실수나 잘못도 많아 데이터 품질이 떨어지면 모델의 성능도 저하될 수 있음
- GPT 이후 대규모 비지도 학습(Unsupervised Learning)이 자연어 처리 작업에서 높은 성능을 발휘할 수 있다는 사실이 입증됨
- 이후 비지도 학습 기반의 사전 학습이 새로운 표준으로 자리 잡음
	- 라벨링 데이터도 필요 없고 수많은 문장을 학습하기만 하면 됨
- 이 부분이 지금의 LLM을 탄생시킨 가장 큰 혁신 중 하나

- 좋은 모델을 만들기 위해서는 학습 데이터의 품질도 중요
	- Garbage in, garbage out : 쓰레기를 넣으면 쓰레기가 나온다. 즉, 품질이 나쁜 문장을 학습하면 엉뚱깽뚱한 답이 나옴
	- 따라서 실용적이고 과학적인 답을 하는 모델을 만드려면 수학, 과학, 의학, 경제, 역사 같은 카테고리의 학습 문장을 사용해야 함


#### 할루시네이션, 환각 또는 환상
- `할루시네이션(Hallucination)` : 존재하지 않는 무언가를 마치 존재하는 것처럼 얘기하는 인공지능의 환각 현상
- 오픈AI의 핵심 연구원 안드레이 카르피시는 LLM이 문장을 생성하는 과정을 두고 마치 꿈을 꾸는 것과 비슷하다고 비유
	- 흐릿한 기억을 바탕으로 꿈속에서도 LLM은 답을 잘하기 위해 최선을 다하지만 그러다가 사실과 다른 영역으로 넘어갈 때가 있음. 그럴 때 할루시네이션이 발생하는 것
- 챗GPT 같은 LLM은 학습 데이터의 양이 매우 방대해서 정보를 그대로 저장하는 게 아니라 압축된 형태로 저장함. 문장을 생성할 때 압축된 정보로부터 복원해서 재구성하기 때문에 이 과정에서 정보의 손실 발생
- 할루시네이션을 문제라기 보다 특징(Feature)로 보는 시각도 있음. 소설, 영화대본 등 창의적인 글쓰기를 할 경우 오히려 도움이 됨

- 할루시네이션 문제를 극복하기 위해서 연구자들이 노력하는 법 : `인간 피드백 기반 강화학습(Reinforcement Learning from Human Feedback, RLHF)`, `검색 증강 생성(Retrieval-Augmented Generation, RAG)`


#### 과연 GPT-4의 비밀은?
- `전문가 혼합(Mixture of Experts, MoE)` : 여러 개의 모델을 만들어두고 필요한 모델만 선택하여 계산하는 구조
	- GPT-4은 2,200억 개의 매개변수를 분야별 8개 모델로 학습하고 게이트를 통해 가중치를 조정하는 전문가 혼합 구조를 사용한다고 추정됨
	- 원래 LLM은 모델 전체가 계싼에 모두 투입되는 구조와 반대로 MoE는 묻는 내용이 과학이면 과학, 수학이면 수학 전문가 모델을 선별적으로 계산해서 불필요한 계산을 줄여주고 정확한 답변을 얻을 수 있게 됨
	- Deepseek 또한 동일한 MoE 구조 활용

- 오픈AI는 기술에 대한 세부 정보를 공개했던 과거와 달리 최근 공개를 하지 않고 있음
	- 오픈 AI 측 이유 : 인간을 뛰어넘을 수 있는 인공지능 기술이 무분별하게 공개될 경우 인류에 위험할 수 있기 때문에 안전하고 책임감 있게 기술을 배포하기 위해서라고 함
	- 마치 핵 기술을 다루는 것과 비슷한 관점으로 접근. 하지만 이는 표면적인 이유이고 자사의 이익 때문에 비공개한게 아니냐라는 비판도 있음

- GPT-4의 기술 비공개가 의미하는 바
	- 언어 모델은 연구 단계를 넘어 제품화 단계에 돌입
		- 오픈AI는 기업에 챗GPT를 유로로 서비스하고 API를 공급하며 본격 플랫폼 비즈니스를 진행하는 제품화 단계에 돌입. 따라서 기술 공개보다는 제품의 완성도를 높이는 방향을 택함
	- 연구 성과로 공개할 내용 부족
		- 챗GPT의 성능이 월등히 향상되긴 했지만 새로운 연구를 도입했다기 보다 기존 모델을 더 다듬고 고도화한 결과였음. 따라서 논문으로 남길 내용이 크게 가능성도 있음


> #### ***comments***
> - p.22 시험문제를 풀려면 단순히 텍스트의 내용뿐 아니라 글자의 위치 정보를 포함한 다양한 정보를 동시에 이해해야 함. 여기서 글자의 위치 정보가 왜 중요한지 설명 안해주시나요...?
> - p.27 리눅스 사례 찾아보기
> - p.29 언어의 의미를 중시한다는 것이 무슨 뜻인지 궁금해서 의미론에 대해 찾아봄
>    - 미셸 브레알의 **의미론** 
>      - 단어의 의미가 시간에 따라 어떻게 변하는지를 체계적으로 연구하는 것이 목표
>            - 언어는 살아 있는 유기체와 같아서 사회·문화·심리적 요인에 의해 끊임없이 진화한다고 함
>        - 언어학은 음운, 문법 뿐만 아니라 의미도 과학적으로 다뤄야 한다고 주장하며 의미론을 음성학, 통사론과 나란히 놓을 수 있는 독립적인 연구 영역으로 제시
> - p.30 조건부 확률(conditional probability) : P(A ∣ B)
>    - B가 주어졌을 때 A의 확률(P) = Probability of A given B
> - p.31, 33 자연어 처리 분야, 파라미터에 대해 찾아보기
> - p.37 바로 전 문단에서는 이제 인공지능 모델들의 비지도 학습 가능해서 학습 데이터가 필요 없다는 식으로 말했는데 왜 다름 문단에서는 학습 데이터 품질에 대해 논하는건지? 비지도 학습에서도 학습 데이터가 필요하지만 라벨링된 학습 데이터는 필요하지 않다는 의미였나?
> - p.41 Ted Chiang 언급된거 보고 다음 책은 SF 소설도 괜찮겠다라고 생각했음 (류츠신, 테드창 등)
> - p.45 일론 머스크와 오픈AI 소송 내용 궁금하네
> - 전반적으로 1장이라서 그런지 이전 작과 유사한 내용이 많아서 조금 중복적이라고 생각한 부분이 있었다. 다만 전작을 읽을 때와 지식이 조금 더 쌓였다고 잘 이해되는 부분도 있었고 더 디테일적인 부분을 찾아볼 수 있었던게 장점이었던 것 같다.

> #### ***food for thought***
> - p.43 George Hotz 팟캐스트 들어보고 싶어서 찾아보니 23년도 인터뷰 발견. 거기서 훗날 자기 친구나 가족들이 실제 자신보다 모델 버전인 George Hotz를 더 좋아할 수도 있을거라는 말에 충격 받음.
> - 정말 내 주변 사람들이 나보다 인공지능 모델 버전인 나를 더 좋아한다면 어떤 생각이 들까? 그리고 나보다 나은 내 버전이 존재한다면 실제 나의 존재의 의미는 무엇일까?