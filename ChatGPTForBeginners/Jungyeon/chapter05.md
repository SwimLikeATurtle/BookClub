## 제5장 프롬프트 엔지니어링의 마법

#### 프롬프트 엔지니어링으로 원하는 결과 얻기
- `프롬프트 엔지니어링(Prompt Engineering)`: LLM이 최적의 결과를 생성할 수 있도록 체계적으로 프롬프트를 최적화하는 전문적인 접근방식식
- LLM이 어떻게 답변해야 하는지 구체적으로 맥락(context)을 제공할수록 효과적인 응답을 얻을 수 있음


#### 예시를 보여주면 더 좋은 결과를 보여드립니다
- `제로샷(Zero-Shot)`: 예시 없이 즉시 추론을 수행
    - 프롬프트에 참조할 수 있는 정보가 없다보니 답변에 한계 존재
- `원샷(One-Shot)`: 예시 하나 제공 후 추론을 수행하게 하는 것
- `퓨샷(Few-Shot)`: 예시 두개 이상 제공 후 추론을 수행하게 하는 것
    - 예시를 여러 개 제공해서 더 일관된 답변 얻을 수 있음. 따라서 제로샷보다 퓨샷을 사용했을 때 성능이 더 좋음

#### 생각의 사슬, 복잡한 문제를 단계적으로 풀기
- `생각의 사슬(Chain of Thought, CoT)`: 추론 단계의 과정을 명확하게 제시해서 답변의 정확도를 높이는 기법이며 특히 복잡한 논리나 추론 작업에서 LLM의 성능을 크게 향상 시킴
    - 인간의 사고 과정에서 생각의 흐름이 중요하듯이 LLM도 답변을 잘하기 위해서는 생각의 사슬이 중요
- CoT는 정답을 가이드하기 위한 예시를 제공하는 형태로 활용되기 때문에 일반적으로 굳이 언급하지 않는 이상 기본적으로 `퓨샷 CoT`가 됨
- 하지만 프롬프트 말미에 '단계별로 천천히 생각해보자(Let's think step by step)'이라는 문구를 추가해서 `제로샷 CoT`로 사용 가능
- CoT의 장점
    1) 사람의 문제 해결 방식과 유사한 단계별 사고 과정을 모방하기 때문. 복잡한 문제를 더 작고 관리하기 쉬운 부분으로 나눠서 처리
    2) 중간 추론 단계를 명시적으로 표현해서 각 단계에서 정확한 판단을 내릴 수 있고 오류 수정이 용이


#### RAG, 검색으로 성능을 높이는 마법
- `검색 증강 생성(RAG)`: 검색 기능을 활용해서 답변 내용을 보완하여 LLM의 생성 능력을 증강 시키는 기법
- RAG는 LLM의 고질적인 문제인 할루시네이션 방지 가능
- 한번 만든 모델은 쉽게 변경하기 어렵지만 RAG를 통해 최신 정보를 주입해 언제든지 정보를 변경하고 정보 출처를 관리할 수 있어 생성된 응답의 내용과 맥락을 더 상세히 제어할 수 있음(ex. 민감 정보 노출되지 않도록 제어 가능)
- Perplexity는 RAG를 유료로 서비스하는 회사
- `랭체인(LangChain)`: RAG를 직접 구축할 수 있도록 지원하는 무료 프레임워크
    - LLM을 활용해 RAG를 개발할 수 있도록 외부 데이터 소스, API, 다양한 외부 환경과 연결하는 작업 등을 하나의 블록처럼 두고 필요한걸 조립해서 서비스를 구성할 수 있게 해주는 프레임워크

#### 벡터 데이터베이스, LLM의 성능을 높이는 또 다른 기술
- `벡터 데이터베이스(Vector Database)`: 단어나 문자의 특징을 숫자 벡터로 변환(임베딩)하여 저장하고 검색할 수 있는 데이터베이스 시스템
    - 검색을 용이하게 하기 위해 데이터를 벡터로 변환해서 보관
- `임베딩`: 단어의 특징을 컴퓨터가 계산할 수 있도록 숫자로 표현하는 과정
    - ex. 사과 [0.2, 0.1, 1.0]
    - 임베딩에 쓰인 숫자를 `벡터`라고 함. 즉, `벡터`는 순서가 있는 숫자의 모음
- 특히, 회사 내부 자료 등 기업의 기밀 데이터를 활용할 경우 벡터 데이터베이스 활용
- 아울러 검색 시스템은 기본적으로 키워드에 일치하는 문서를 찾는 구조를 갖고 있지만 벡터 데이터베이스는 숫자 값을 이용해 비슷한 숫자를 찾는 형태이기 때문에 해당 키워드가 포함되어 있지 않거나 완전 다른 내용도 검색 가능
    - 즉, 벡터 데이터베이스는 의미론적 검색(Semantic Search)이 가능
- 벡터 데이터베이스로 주목 받고 있는 회사는 파인콘(Pinecone), 밀버스 (Milvus), 일래스틱서치(Elasticsearch)


#### 고급 프롬프트 엔지니어링 기법을 소개하며
- `생각의 나무(Tree of Thought)`: 생각의 사슬에서 확장된 개념이며 여러 가능성을 고려한 후 가장 적절한 답을 찾도록 유도하는 방식
    - 다양한 후보를 탐색해야 되서 시간이 오래 걸리지만 추론에 시간을 더 많이 할애하여 모델의 성능을 높일 수 있음
-  `토론 프롬프팅(Debate Prompting)`: LLM을 서로 다른 관점에서 논쟁하게 만든 후 최적의 답을 도출하는 방식
    - 공평한 답, 최적의 답을 찾는데 도움이 되지만 많은 시간 소요. ToT처럼 추론에 시간을 많이 할애해서 성능을 높인 방식
- 이 외에도 페르소나 주입, 프롬프트 형식 지정 방식, 실행 형식 정의 후 실행 결과를 유도하는 방식 등 다양한 고급 프롬프트 엔지니어링 기법 존재


#### 오픈AI o1, 생각을 거듭할수록 더 좋은 결과를 제시하다
- 2024년 9월 오픈AI가 공개한 o1 모델은 '생각하는 과정'을 거쳐 답변을 고도화하는데 사람이 프롬프트 엔지니어링으로 더 좋은 답변을 도출하는 과정을 자동화해서 스스로 처리함 (마치 생각의 나무나 토론 프롬프팅을 자동화한 것과 비슷)
- 이제 모델만으로 성능을 높이기 쉽지 않기 대문에 o1처럼 추론 단계에서 다양한 기법을 활용해서 성능을 높이는 방법이 많이 연구되고 있음
- 모델의 성능은 크기, 데이터 양, 학습 비용(계산량)이 증가하면 이에 비례해 개선되는데 계산량(추론)을 증가해서 개선하는 것이 o1이 추구하는 방향
- `테스트 타임 스케일링(Test-Time Scaling)`: 추론 과정에 시간을 할애해서 성능을 높이는 기법

#### 딥시크 R1, 엔비디아 주가를 18% 폭락시킨 중국의 힘
- 딥시크 R1은 o1 모델과 동일하게 생각하는 과정을 도입해 성능을 높임
- 중국은 미국의 제재 때문에 최상급 GPU인 H100 사용에 제한이 있음에도 불구하고 저사양 GPU를 이용해 o1 모델 보다 더 좋은 결과를 만들어내서 미국에게 충격을 줌
- R1은 GPT-4와 o1의 구조를 동일하게 따라해서 만듦 
    - 여러 개의 모델을 만들어두고 필요한 모델만 선택하는 방식인 MoE(Mixture of Experts)구조 채택했으며 RLHF(Reinforcement Learning from Human Feedback)이라는 강화학습 기법 활용
    - 단, 외부 평가자가 답안을 평가하고 보상하는 대신 답변끼리 비교하며 상대적 순위를 매기고 순위가 높은 답안에 더 많은 보상을 부여하는 방식
    - o1 모델처럼 답변을 내기까지 추론이나 사고과정을 기록하여 내부 로직을 개선하고 정교한 답변을 만듦
- 딥시크 논문에서는 퓨샷으로 예시를 주면 성능이 더 떨어진다고 밝힘
- 딥시크는 오픈AI와 달리 R1 모델을 오픈소스로 풀어버렸고 앞으로 이 분야의 연구가 늘어날 것으로 예상
- 추론에 시간을 할애할수록 성능이 더 높아진다는 `테스트 타임 스케일링` 또한 더 중요한 개념으로 부상할 예정


> #### ***comments***
- p.194 인터넷 정보검색사가 유망한 직종으로 각광받던 시절이 있었지만 검색이 일상화되면서 시대의 흐름 속에 사라짐. 프롬프트 엔지니어도 앞으로 필요 없는 기술이 될 수도...
- p.219 제이슨 웨이(Jason Wei)는 구글 재직 당시 생각의 사슬 만듦


> #### ***food for thought***
> - 인공지능 모델이 프롬프트 엔지니어링을 자동화하게 되며 앞으로는 개별적으로 프롬프트 엔지니어링을 공부하지 않아도 좋은 답변을 얻을 수 있다면 인공지능을 잘 활용하고 아니고의 차이는 어디에서 둘 수 있을까?
    - Context Engineering : 단순히 질문을 잘 던지는 '프롬프트 엔지니어링'을 넘어 AI가 최선의 답변을 낼 수 있도록 정보의 환경과 데이터 흐름을 설계하는 전문 분야로 부상. 즉 AI가 참고할 지식과 상황을 어떻게 구조화해서 보여줄 것인가를 연구하는 것